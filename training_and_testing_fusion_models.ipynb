{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This repo contains the following:\n",
    "- Code for CNN-based classification for MNIST Dataset\n",
    "- Code for Pointnet classification for MNIST3D Dataset\n",
    "- Code for Fusion-based classification for MNIST and MNIST3D Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up and load libraries\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Tensorflow and Keras...\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "# plot and others...\n",
    "from matplotlib import pyplot as plt\n",
    "import trimesh\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "# set seed\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cloud_points = 2048\n",
    "point_cloud_size = (num_cloud_points, 3)\n",
    "image_size = (30, 30, 1)\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "patience = 5\n",
    "\n",
    "# run_type = 'demo'\n",
    "run_type = 'full'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST (2D + 3D) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directory\n",
    "DATADIR = '../data/multimodal/mnist3d/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_type, num_pcs):\n",
    "    '''\n",
    "    Load train and test data: 2D images, 3D point clouds and labels\n",
    "\n",
    "    arg:\n",
    "    data_type: 'train' or 'test'\n",
    "\n",
    "    return:\n",
    "    x_2d: 2D images \n",
    "    x_3d: 3D pointcloud\n",
    "    y: labels\n",
    "    '''\n",
    "    print(f\"Loading {data_type} data......\")\n",
    "\n",
    "    with h5py.File(DATADIR + f'{data_type}_point_clouds.h5', 'r') as points_dataset:\n",
    "\n",
    "        # Array to store data...\n",
    "        x_2d = []\n",
    "        x_3d = []\n",
    "        y = [] \n",
    "\n",
    "        # Looping over the whole dataset..\n",
    "        for i, (key, sample) in enumerate(points_dataset.items()):\n",
    "            \n",
    "            # Saving images...\n",
    "            x_2d.append(sample['img'][:])\n",
    "\n",
    "            # Sampling point cloud and saving...\n",
    "            pointCloud = sample['points'][:]\n",
    "            num_of_rows = pointCloud.shape[0]\n",
    "            random_ind = np.random.choice(num_of_rows, size=num_pcs, replace=False)\n",
    "            pointCloud = pointCloud[random_ind, :]\n",
    "            x_3d.append(pointCloud)\n",
    "\n",
    "            # Ssaving labels...\n",
    "            y.append(sample.attrs['label'])\n",
    "\n",
    "    # converting to np array...\n",
    "    x_2d = np.stack(x_2d).reshape(-1, 30, 30, 1)\n",
    "    x_3d = np.stack(x_3d)\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    y = keras.utils.to_categorical(np.array(y), num_classes)  \n",
    "\n",
    "    # Dropping samples if running as a demo...\n",
    "    \n",
    "    # Total samples..............\n",
    "    total_samples = x_3d.shape[0]\n",
    "    # Taking random indices for resampling\n",
    "    random_indices = np.arange(total_samples)\n",
    "    np.random.shuffle(random_indices)\n",
    "\n",
    "    # checking the run_type\n",
    "    if run_type == 'demo':\n",
    "        print(f\"Original shape of 2D samples: {x_2d.shape}\")\n",
    "        print(f\"Original shape of 3D samples: {x_3d.shape}\")\n",
    "        demo_samples = 100\n",
    "        random_indices = random_indices[0:demo_samples]\n",
    "\n",
    "    # Selecting training and test samples...\n",
    "    x_2d = x_2d[random_indices]\n",
    "    x_3d = x_3d[random_indices]\n",
    "    y = y[random_indices]\n",
    "   \n",
    "    # Done loading and processing dataset...\n",
    "    # print(f\"{data_type} data loaded...!\")\n",
    "    print(f\"_______________________________________________\")\n",
    "    print(f\"Loaded shape of 2D samples: {x_2d.shape}\")\n",
    "    print(f\"Loaded shape of 3D samples: {x_3d.shape}\")\n",
    "    print(\"\\n\")\n",
    "    # return image, pointclouds, and labels\n",
    "    return x_2d, x_3d, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading training data\n",
    "x_train_2d, x_train_3d, y_train = load_data(data_type = 'train', num_pcs = num_cloud_points)\n",
    "y_train_digit = np.argmax(y_train, axis=1) # Convert one-hot to index\n",
    "\n",
    "# Loading test data\n",
    "x_test_2d, x_test_3d, y_test = load_data(data_type = 'test', num_pcs = num_cloud_points)\n",
    "y_test_digit = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_test_df = pd.DataFrame(y_test_digit, columns = ['Label'])\n",
    "\n",
    "x_train_dict = {}\n",
    "x_train_dict['2D'] = x_train_2d\n",
    "x_train_dict['3D'] = x_train_3d\n",
    "x_train_dict['Fusion'] = [x_train_2d, x_train_3d]\n",
    "\n",
    "x_test_dict = {}\n",
    "x_test_dict['2D'] = x_test_2d\n",
    "x_test_dict['3D'] = x_test_3d\n",
    "x_test_dict['Fusion'] = [x_test_2d, x_test_3d]\n",
    "\n",
    "# Creating input for adv sample generation\n",
    "y_test_df_samp = y_test_df.groupby('Label', group_keys=False).apply(lambda x: x.sample(3))\n",
    "y_plot_df_samp = y_test_df_samp.reset_index(drop=True).groupby('Label', group_keys=False).apply(lambda x: x.sample(1))\n",
    "\n",
    "\n",
    "test_ind = y_test_df_samp.index\n",
    "plot_ind = y_plot_df_samp.index\n",
    "\n",
    "x_actual_dict = {}\n",
    "x_actual_dict['2D'] = tf.convert_to_tensor(x_test_2d[test_ind])\n",
    "x_actual_dict['3D'] = tf.convert_to_tensor(x_test_3d[test_ind])\n",
    "x_actual_dict['Fusion'] = [x_actual_dict['2D'], x_actual_dict['3D']]\n",
    "y_actual = tf.convert_to_tensor(y_test[test_ind])\n",
    "y_actual_digit = y_test_df_samp['Label'].values\n",
    "\n",
    "# Loss object..\n",
    "loss_func = tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions \n",
    "def train_and_evaluate(model_name, model_type, fusion_type, fusion_layer, model, epochs, batch_size, patience):\n",
    "    \"\"\"  \n",
    "    arg: model and other info\n",
    "    return: trained model & eval data\n",
    "    \"\"\"\n",
    "    # Train and evaluate model\n",
    "    # Starting the training...\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=patience)\n",
    "    history = model.fit(x_train_dict[model_type], y_train, batch_size=batch_size\n",
    "    , epochs=epochs, validation_split=0.1, callbacks=[callback])\n",
    "\n",
    "    # Evaluate model on test data...\n",
    "    accuracy = model.evaluate(x_test_dict[model_type], y_test, batch_size=56)[1]\n",
    "    # print(f\"Test Accuracy of {model_name}: {np.round(accuracy*100,5)}%\")\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.plot(history.history['loss'], marker = 'p')\n",
    "    plt.title(f\"Test Accuracy of {model_name}: {np.round(accuracy*100,5)}%\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/training_histiry_{model_name}_{model_type}.jpg' , dpi = 350)\n",
    "    plt.show()\n",
    "\n",
    "    # Classification matrix...\n",
    "    y_pred = np.argmax(model.predict(x_test_dict[model_type]), axis=1)\n",
    "    cls_rep = classification_report(y_test_digit, y_pred) \n",
    "\n",
    "    model_eval = {\n",
    "        'fusion_type': fusion_type,\n",
    "        'fusion_layer': fusion_layer,\n",
    "        'model': model,\n",
    "        'model_name' : model_name,\n",
    "        'model_type': model_type,\n",
    "        'history': history,\n",
    "        'accuracy': accuracy,\n",
    "        'cls_rep' : cls_rep\n",
    "    }   \n",
    "    #-------------------------\n",
    "    return model_eval\n",
    "\n",
    "def visualize_prediction(model_name, model_type, model, vis_type):\n",
    "    \"\"\" \n",
    "    Visualize the prediction performance\n",
    "    arg: \n",
    "    model_type: '2D' , '3D' or 'Fusion'\n",
    "    model: keras model\n",
    "\n",
    "    return:\n",
    "    plot the first 10 samples with predicted labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Visualize predictions and images...\n",
    "    noOfsamples = 5 if model_type =='Fusion' else 10\n",
    "    if vis_type == 'Actual':\n",
    "        # images, points, labels = x_test_2d[:noOfsamples], x_test_3d[:noOfsamples], y_test[:noOfsamples]\n",
    "        images, points, labels = x_actual_dict['2D'].numpy()[plot_ind][:noOfsamples], x_actual_dict['3D'].numpy()[plot_ind][:noOfsamples], y_actual.numpy()[plot_ind][:noOfsamples]\n",
    "        \n",
    "    elif vis_type == 'Adversarial':\n",
    "        if model_type =='2D' or model_type =='Fusion':\n",
    "            images, labels = x_adv_dict['2D'].numpy()[plot_ind][:noOfsamples], y_actual.numpy()[plot_ind][:noOfsamples]\n",
    "        if model_type =='3D' or model_type =='Fusion':\n",
    "            points, labels = x_adv_dict['3D'].numpy()[plot_ind][:noOfsamples], y_actual.numpy()[plot_ind][:noOfsamples]\n",
    "\n",
    "    # Setting up input data for the prediction\n",
    "    if model_type == '2D':\n",
    "        input_data = images\n",
    "    elif model_type == '3D':\n",
    "        input_data = points\n",
    "    elif model_type =='Fusion':\n",
    "        input_data = [images, points]\n",
    "        \n",
    "\n",
    "    # run test data through model\n",
    "    \n",
    "    if vis_type == 'Actual':\n",
    "        preds = model.predict(input_data)\n",
    "        preds = tf.math.argmax(preds, -1).numpy()\n",
    "    else:\n",
    "        preds = y_adv_pred_digit[0:noOfsamples]\n",
    "        # labels = y_actual_digit[0:noOfsamples]\n",
    "    \n",
    "    labels = np.argmax(labels, axis = 1)\n",
    "\n",
    "\n",
    "    # plot points with predicted class and label\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    # Looping over the input sample to visualization\n",
    "    for i in range(noOfsamples):\n",
    "        # print(f\"pred: {preds[i]}, label: {labels[i]}\") \n",
    "        \n",
    "        if model_type == '2D' or model_type == 'Fusion':\n",
    "            if model_type != 'Fusion':\n",
    "                index = i+1\n",
    "            else:\n",
    "                index = i+1\n",
    "            ax = fig.add_subplot(2, 5, index)\n",
    "            ax.imshow(images[i, :, :, 0])\n",
    "            ax.set_title(\n",
    "                \"Pred: {:}, Label: {:}\".format(\n",
    "                    preds[i], labels[i]\n",
    "                )\n",
    "            )\n",
    "            ax.set_axis_off()\n",
    "\n",
    "        if model_type == '3D' or model_type == 'Fusion':\n",
    "            if model_type != 'Fusion':\n",
    "                index = i+1\n",
    "            else:\n",
    "                index = noOfsamples+i+1\n",
    "            ax = fig.add_subplot(2, 5, index, projection=\"3d\")    \n",
    "            ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2], marker='.')\n",
    "            # ax.set_axis_off()\n",
    "            if model_type != 'Fusion':\n",
    "                ax.set_title(\"Pred: {:}, Label: {:}\".format(\n",
    "                    preds[i], labels[i]))\n",
    "            ax.set_xticks([])\n",
    "            ax.grid(True)\n",
    "            ax.view_init(0, 10)\n",
    "    fig.suptitle(f\"Visualizing Prediction of Model: {model_name} Under {vis_type} Condition\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/vis_predict_{model_name}_{model_type}_{vis_type}.jpg' , dpi = 350)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Models to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for building the models.......\n",
    "\n",
    "# Convolution with batch normalization...\n",
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "# Dense with batch normalization...\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "# Transormation Network (T-Net)...\n",
    "def tnet(inputs, num_features):\n",
    "    # Initalise bias as the indentity matrix\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    # reg = OrthogonalRegularizer(num_features)\n",
    "    x = conv_bn(inputs, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        # activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    # Apply affine transformation to input features\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model to extract 128 features from 2D MNIST dataset\n",
    "inputs_2D = Input(shape=image_size)\n",
    "feat_2d = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inputs_2D)\n",
    "feat_2d = MaxPooling2D(pool_size=(2, 2))(feat_2d)\n",
    "feat_2d = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(feat_2d)\n",
    "feat_2d = MaxPooling2D(pool_size=(2, 2))(feat_2d)\n",
    "feat_2d = Flatten()(feat_2d)\n",
    "feat_2d = Dropout(0.3)(feat_2d)\n",
    "feat_2d = Dense(128, activation=\"relu\")(feat_2d)\n",
    "# Creating the model to extract features from input images\n",
    "model_feat_ext_2D = Model(inputs=inputs_2D, outputs=feat_2d,  name=\"feature-extractor-2D\")\n",
    "print(model_feat_ext_2D.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pointnet model to extract 128 features from 3D MNIST dataset\n",
    "inputs_3D = Input(shape= point_cloud_size)\n",
    "\n",
    "feat_3D = tnet(inputs_3D, 3)\n",
    "feat_3D = conv_bn(feat_3D, 32)\n",
    "feat_3D = conv_bn(feat_3D, 32)\n",
    "feat_3D = tnet(feat_3D, 32)\n",
    "feat_3D = conv_bn(feat_3D, 32)\n",
    "feat_3D = conv_bn(feat_3D, 64)\n",
    "feat_3D = conv_bn(feat_3D, 512)\n",
    "feat_3D = GlobalMaxPooling1D()(feat_3D)\n",
    "feat_3D = dense_bn(feat_3D, 256)\n",
    "feat_3D = Dropout(0.3)(feat_3D)\n",
    "feat_3D = dense_bn(feat_3D, 128)\n",
    "# Creating the model to extract features from input point cluds\n",
    "model_feat_ext_3D = Model(inputs=inputs_3D, outputs=feat_3D,  name=\"feature-extractor-3D\")\n",
    "print(model_feat_ext_3D.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing model eval data...\n",
    "model_eval_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating 2D CNN-based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to predict score for 128 features for MNIST\n",
    "feats_extracted_2D = Input(shape= feat_2d.shape[1:])  \n",
    "output_pred_2D = Dense(num_classes, activation=\"softmax\")(feats_extracted_2D)\n",
    "model_pred_scores_2D = Model(feats_extracted_2D, output_pred_2D)\n",
    "# model_pred_scores_2D.summary()\n",
    "\n",
    "# Model 2D CNN-based Classifier for MNIST 2D\n",
    "# Complete CNN model for MNIST 2D Dataset\n",
    "model_2D_mnist = keras.Model(inputs_2D, model_pred_scores_2D(model_feat_ext_2D(inputs_2D)))\n",
    "model_2D_mnist.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(model_2D_mnist.summary())\n",
    "\n",
    "\n",
    "model_name = 'model_2D_mnist'\n",
    "model = model_2D_mnist\n",
    "model_type = '2D'\n",
    "fusion_type = None\n",
    "fusion_layer = None\n",
    "\n",
    "# Train and evaluate...\n",
    "model_eval_dict[model_name]= train_and_evaluate(\n",
    "    model_name, model_type, fusion_type, fusion_layer, model, epochs, batch_size, patience)\n",
    "# # Visualize the prediction on 3D point clouds\n",
    "visualize_prediction(model_name, model_type, model, vis_type= 'Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating 3D Pointnet-based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to predict score for 128 features for MNIST 3D dataset\n",
    "feats_extracted_3D = Input(shape= feat_3D.shape[1:])  \n",
    "output_pred_3D = Dense(num_classes, activation=\"softmax\")(feats_extracted_3D)\n",
    "model_pred_scores_3D = Model(feats_extracted_3D, output_pred_3D)\n",
    "# model_pred_scores_3D.summary()\n",
    "\n",
    "# Model Pointnet Classifier for MNIST 3D\n",
    "model_3D_mnist = keras.Model(inputs_3D, model_pred_scores_3D(model_feat_ext_3D(inputs_3D)))\n",
    "model_3D_mnist.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(model_3D_mnist.summary())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_name = 'model_3D_mnist'\n",
    "model = model_3D_mnist\n",
    "model_type = '3D'\n",
    "fusion_type = None\n",
    "fusion_layer = None\n",
    "\n",
    "# epochs = 1 \n",
    "# batch_size = 32\n",
    "# patience = 5\n",
    "# x_train = x_train_3d\n",
    "# x_test = x_test_3d\n",
    "\n",
    "# Train and evaluate...\n",
    "model_eval_dict[model_name]= train_and_evaluate(\n",
    "    model_name, model_type, fusion_type, fusion_layer, model, epochs, batch_size, patience)\n",
    "\n",
    "# # Visualize the prediction on 3D point clouds\n",
    "visualize_prediction(model_name, model_type, model, vis_type= 'Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Fusion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Late Fusion Models with different fusion layers\n",
    "from keras.layers import Concatenate, Average,Maximum, Minimum, Add, Subtract, Multiply\n",
    "\n",
    "mid_fusion_layers_dict = {\n",
    "    'concatenate': Concatenate(),\n",
    "    'Average' : Average(),\n",
    "    'Maximum' : Maximum(),\n",
    "    'Minimum' : Minimum(),\n",
    "    # 'Add': Add(),\n",
    "    # 'Subtract': Subtract(),\n",
    "    'Multiply': Multiply()\n",
    "}\n",
    "\n",
    "\n",
    "late_fusion_layers_dict = {\n",
    "    'Average' : Average(),\n",
    "    'Maximum' : Maximum(),\n",
    "    'Minimum' : Minimum(),\n",
    "    # 'Add': Add(),\n",
    "    # 'Subtract': Subtract(),\n",
    "    'Multiply': Multiply()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feat_ext_2D.trainable = False\n",
    "model_feat_ext_3D.trainable = False\n",
    "\n",
    "model_pred_scores_2D.trainable = False\n",
    "model_pred_scores_3D.trainable = False\n",
    "\n",
    "model_2D_mnist.trainable = False\n",
    "model_3D_mnist.trainable = False\n",
    "\n",
    "# model_feat_ext_2D.trainable = True\n",
    "# model_feat_ext_3D.trainable = True\n",
    "\n",
    "# model_pred_scores_2D.trainable = True\n",
    "# model_pred_scores_3D.trainable = True\n",
    "\n",
    "# model_2D_mnist.trainable = True\n",
    "# model_3D_mnist.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Late-Fusion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fusion_layer_name, fusion_layer in late_fusion_layers_dict.items():\n",
    "\n",
    "    print(fusion_layer_name)\n",
    "    model_name = f\"model_late_fusion_mnist_{fusion_layer_name}\"\n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    output_pred_late_fusion = fusion_layer([model_2D_mnist.output, model_3D_mnist.output])\n",
    "\n",
    "    # Finally combine two models and build a single multi modal mode...\n",
    "    model_late_fusion_mnist = Model(inputs=[inputs_2D, inputs_3D], outputs= output_pred_late_fusion,  name = model_name)\n",
    "    model_late_fusion_mnist.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    # print(model_late_fusion_mnist.summary())\n",
    "\n",
    "    model_name = model_name\n",
    "    model = model_late_fusion_mnist\n",
    "    model_type = 'Fusion'\n",
    "    fusion_type = \"Late\"\n",
    "    fusion_layer = fusion_layer_name\n",
    "    # epochs = 2 \n",
    "    # batch_size = 32\n",
    "    # patience = 5\n",
    "    # x_train = [x_train_2d, x_train_3d]\n",
    "    # x_test = [x_test_2d, x_test_3d]\n",
    "\n",
    "    # Train and evaluate...\n",
    "    model_eval_dict[model_name]= train_and_evaluate(\n",
    "        model_name, model_type, fusion_type, fusion_layer, model, epochs, batch_size, patience)\n",
    "\n",
    "    # # Visualize the prediction on 3D point clouds\n",
    "    visualize_prediction(model_name, model_type, model, vis_type= 'Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Mid Fusion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fusion_layer_name, fusion_layer in mid_fusion_layers_dict.items():\n",
    "\n",
    "    print(fusion_layer_name)\n",
    "    model_name = f\"model_mid_fusion_mnist_{fusion_layer_name}\"\n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    output_pred_mid_fusion = fusion_layer([model_feat_ext_2D.output, model_feat_ext_3D.output])\n",
    "    output_pred_mid_fusion = Dense(128, activation=\"relu\")(output_pred_mid_fusion)\n",
    "    output_pred_mid_fusion = Dense(64, activation=\"relu\")(output_pred_mid_fusion)\n",
    "    output_pred_mid_fusion = Dense(num_classes, activation=\"softmax\")(output_pred_mid_fusion)\n",
    "\n",
    "    # Finally combine two models and build a single multi modal mode...\n",
    "    model_mid_fusion_mnist = Model(inputs=[inputs_2D, inputs_3D], outputs= output_pred_mid_fusion,  name = model_name)\n",
    "    model_mid_fusion_mnist.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    # print(model_late_fusion_mnist.summary())\n",
    "\n",
    "    model_name = model_name\n",
    "    model = model_mid_fusion_mnist\n",
    "    model_type = 'Fusion'\n",
    "    fusion_type = \"Mid\"\n",
    "    fusion_layer = fusion_layer_name\n",
    "\n",
    "\n",
    "    # Train and evaluate...\n",
    "    model_eval_dict[model_name]= train_and_evaluate(\n",
    "        model_name, model_type, fusion_type, fusion_layer, model, epochs, batch_size, patience)\n",
    "\n",
    "    # # Visualize the prediction on 3D point clouds\n",
    "    visualize_prediction(model_name, model_type, model, vis_type= 'Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Savind data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = ['fusion_type', 'fusion_layer', 'model_name', 'model_type', 'accuracy']\n",
    "\n",
    "eval_data = {}\n",
    "\n",
    "for model_name in tqdm(model_eval_dict.keys()):\n",
    "    \n",
    "    value = model_eval_dict[model_name]\n",
    "    values = []\n",
    "    for feat in feat_list:\n",
    "        values.append(value[feat])\n",
    "    eval_data[model_name] = values\n",
    "\n",
    "    model = model_eval_dict[model_name]['model']\n",
    "    model.save(f'models/{model_name}')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model evalution data on actual dataset...\n",
    "model_eval_actual = pd.DataFrame(eval_data,feat_list).T\n",
    "model_eval_actual.to_csv(\"generated_data/model_eval_actual.csv\", header = True, index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76b18d0804b1d18cc4a8723b732596a057f641d6427a46ef33e32599b5d9a6a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
