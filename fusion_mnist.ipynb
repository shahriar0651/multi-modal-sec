{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This repo contains the following:\n",
    "- Code for CNN-based classification for MNIST Dataset\n",
    "- Code for Pointnet classification for MNIST3d Dataset\n",
    "- Code for Fusion-based classification for MNIST and MNIST3D Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "tf.random.set_seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for device in gpu_devices:\n",
    "#     tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '../data/multimodal/mnist3d/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File(DATADIR + 'full_dataset_vectors.h5', 'r') as dataset:\n",
    "#     X_train = dataset['X_train'][:]\n",
    "#     X_test = dataset['X_test'][:]\n",
    "#     y_train = dataset['y_train'][:]\n",
    "#     y_test = dataset['y_test'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noOfpoints = 2048\n",
    "BATCH_SIZE = 32\n",
    "run_type = 'demo'\n",
    "run_type = 'full'\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "num_classes = NUM_CLASSES\n",
    "NUM_POINTS = noOfpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(DATADIR + 'train_point_clouds.h5', 'r') as points_dataset:\n",
    "\n",
    "    # Array to store data...\n",
    "    x_train_2d = []\n",
    "    x_train_3d = []\n",
    "    y_train = [] \n",
    "\n",
    "    # Looping over the whole dataset..\n",
    "    for i, (key, sample) in enumerate(points_dataset.items()):\n",
    "        \n",
    "        # Saving images...\n",
    "        x_train_2d.append(sample['img'][:])\n",
    "\n",
    "        # Sampling point cloud and saving...\n",
    "        pointCloud = sample['points'][:]\n",
    "        num_of_rows = pointCloud.shape[0]\n",
    "        random_ind = np.random.choice(num_of_rows, size=noOfpoints, replace=False)\n",
    "        pointCloud = pointCloud[random_ind, :]\n",
    "        x_train_3d.append(pointCloud)\n",
    "\n",
    "        # Ssaving labels...\n",
    "        y_train.append(sample.attrs['label'])\n",
    "\n",
    "# converting to np array...\n",
    "x_train_2d = np.stack(x_train_2d)\n",
    "x_train_3d = np.stack(x_train_3d)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(DATADIR + 'test_point_clouds.h5', 'r') as points_dataset:\n",
    "\n",
    "    # Array to store data...\n",
    "    x_test_2d = []\n",
    "    x_test_3d = []\n",
    "    y_test = [] \n",
    "\n",
    "    # Looping over the whole dataset..\n",
    "    for i, (key, sample) in enumerate(points_dataset.items()):\n",
    "        \n",
    "        # Saving images...\n",
    "        x_test_2d.append(sample['img'][:])\n",
    "\n",
    "        # Sampling point cloud and saving...\n",
    "        pointCloud = sample['points'][:]\n",
    "        num_of_rows = pointCloud.shape[0]\n",
    "        random_ind = np.random.choice(num_of_rows, size=noOfpoints, replace=False)\n",
    "        pointCloud = pointCloud[random_ind, :]\n",
    "        x_test_3d.append(pointCloud)\n",
    "\n",
    "        # Ssaving labels...\n",
    "        y_test.append(sample.attrs['label'])\n",
    "\n",
    "# converting to np array...\n",
    "x_test_2d = np.stack(x_test_2d)\n",
    "x_test_3d = np.stack(x_test_3d)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset for mnist 3D data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding extra...\n",
    "\n",
    "total_training_samples = x_train_3d.shape[0]\n",
    "total_testing_samples = x_test_3d.shape[0]\n",
    "\n",
    "random_trainig_indices = np.arange(total_training_samples)\n",
    "np.random.shuffle(random_trainig_indices)\n",
    "\n",
    "random_testing_indices = np.arange(total_testing_samples)\n",
    "np.random.shuffle(random_testing_indices)\n",
    "\n",
    "\n",
    "print(f\"No of training samples: {x_train_3d.shape[0]}\")\n",
    "print(f\"No of testing samples: {x_test_3d.shape[0]}\")\n",
    "\n",
    "\n",
    "if run_type == 'demo':\n",
    "    demo_training_samples = 100\n",
    "    demo_testing_samples = 100\n",
    "\n",
    "    random_trainig_indices = random_trainig_indices[0:demo_training_samples]\n",
    "    random_testing_indices = random_testing_indices[0:demo_testing_samples]\n",
    "\n",
    "x_train_2d_sel = x_train_2d[random_trainig_indices]\n",
    "x_train_3d_sel = x_train_3d[random_trainig_indices]\n",
    "y_train_sel = y_train[random_trainig_indices]\n",
    "\n",
    "x_test_2d_sel = x_test_2d[random_testing_indices]\n",
    "x_test_3d_sel = x_test_3d[random_testing_indices]\n",
    "y_test_sel = y_test[random_testing_indices]\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train_sel_b = keras.utils.to_categorical(y_train_sel, num_classes)\n",
    "y_test_sel_b = keras.utils.to_categorical(y_test_sel, num_classes)\n",
    "\n",
    "# Reshaping 2D images to add additional dimension\n",
    "x_train_2d_sel = x_train_2d_sel.reshape(-1, 30, 30, 1)\n",
    "x_test_2d_sel = x_test_2d_sel.reshape(-1, 30, 30, 1)\n",
    "\n",
    "print(\"After updating...\")\n",
    "print(f\"No of training samples: {x_train_3d_sel.shape[0]}\")\n",
    "print(f\"No of testing samples: {y_train_sel.shape[0]}\")\n",
    "print(\"Done...!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_2d = tf.data.Dataset.from_tensor_slices((x_train_2d_sel, y_train_sel))\n",
    "test_dataset_2d = tf.data.Dataset.from_tensor_slices((x_test_2d_sel, y_test_sel))\n",
    "\n",
    "train_dataset_3d = tf.data.Dataset.from_tensor_slices((x_train_3d_sel, y_train_sel))\n",
    "test_dataset_3d = tf.data.Dataset.from_tensor_slices((x_test_3d_sel, y_test_sel))\n",
    "\n",
    "\n",
    "\n",
    "# Adding augment and creating dataset...\n",
    "def augment(points, label):\n",
    "    # jitter points\n",
    "    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n",
    "    # shuffle points\n",
    "    points = tf.random.shuffle(points)\n",
    "    return points, label\n",
    "\n",
    "\n",
    "train_dataset_2d = train_dataset_2d.shuffle(len(x_train_2d_sel)).map(augment).batch(BATCH_SIZE)\n",
    "test_dataset_2d = test_dataset_2d.shuffle(len(x_test_2d_sel)).batch(BATCH_SIZE)\n",
    "\n",
    "train_dataset_3d = train_dataset_3d.shuffle(len(x_train_3d_sel)).map(augment).batch(BATCH_SIZE)\n",
    "test_dataset_3d = test_dataset_3d.shuffle(len(x_test_3d_sel)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model\n",
    "\n",
    "Each convolution and fully-connected layer (with exception for end layers) consits of\n",
    "Convolution / Dense -> Batch Normalization -> ReLU Activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PointNet consists of two core components. The primary MLP network, and the transformer\n",
    "net (T-net). The T-net aims to learn an affine transformation matrix by its own mini\n",
    "network. The T-net is used twice. The first time to transform the input features (n, 3)\n",
    "into a canonical representation. The second is an affine transformation for alignment in\n",
    "feature space (n, 3). As per the original paper we constrain the transformation to be\n",
    "close to an orthogonal matrix (i.e. ||X*X^T - I|| = 0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "#     def __init__(self, num_features, l2reg=0.001):\n",
    "#         self.num_features = num_features\n",
    "#         self.l2reg = l2reg\n",
    "#         self.eye = tf.eye(num_features)\n",
    "\n",
    "#     def __call__(self, x):\n",
    "#         x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "#         xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "#         xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "#         return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can then define a general function to build T-net layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tnet(inputs, num_features):\n",
    "\n",
    "    # Initalise bias as the indentity matrix\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    # reg = OrthogonalRegularizer(num_features)\n",
    "    x = conv_bn(inputs, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        # activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    # Apply affine transformation to input features\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main network can be then implemented in the same manner where the t-net mini models\n",
    "can be dropped in a layers in the graph. Here we replicate the network architecture\n",
    "published in the original paper but with half the number of weights at each layer as we\n",
    "are using the smaller 10 class ModelNet dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
    "\n",
    "x = tnet(inputs, 3)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = tnet(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 512)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 128)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "Once the model is defined it can be trained like any other standard classification model\n",
    "using `.compile()` and `.fit()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "batch_size = 20\n",
    "epochs = 2\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train_3d_sel, y_train_sel_b, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     loss=\"sparse_categorical_crossentropy\",\n",
    "#     optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "#     metrics=[\"sparse_categorical_accuracy\"],\n",
    "# )\n",
    "\n",
    "# model.fit(train_dataset_3d, epochs = 10, validation_data=test_dataset_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "model.save('models/mnist3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = keras.models.load_model('models/mnist3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions\n",
    "\n",
    "We can use matplotlib to visualize our trained model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_dataset_3d.take(1)\n",
    "\n",
    "points, labels = list(data)[0]\n",
    "points = points[:8, ...]\n",
    "labels = labels[:8, ...]\n",
    "\n",
    "# run test data through model\n",
    "preds = model.predict(points)\n",
    "preds = tf.math.argmax(preds, -1)\n",
    "\n",
    "points = points.numpy()\n",
    "\n",
    "# plot points with predicted class and label\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n",
    "    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2], marker = '.')\n",
    "    ax.set_title(\n",
    "        \"pred: {:}, label: {:}\".format(\n",
    "            preds[i].numpy(), labels.numpy()[i]\n",
    "        )\n",
    "    )\n",
    "    ax.set_axis_off()\n",
    "    ax.view_init(5, 15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = x_test_3d_sel[0:1]\n",
    "label = y_test_sel_b[0:1]\n",
    "\n",
    "\n",
    "# plot points with predicted class and label\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n",
    "ax.scatter(image[:, 0], image[:, 1], image[:, 2])\n",
    "ax.set_axis_off()\n",
    "ax.view_init(5, 15)\n",
    "plt.title(label)\n",
    "plt.show()\n",
    "\n",
    "# image = tf.Tensor(image, dtype = float)\n",
    "# label = tf.Tensor(label, dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = x_test_3d_sel[0:1]\n",
    "label = y_test_sel_b[0:1]\n",
    "\n",
    "image = tf.convert_to_tensor(image)\n",
    "label = tf.convert_to_tensor(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def create_adversarial_pattern(model, input_image, input_label):\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(input_image)\n",
    "    prediction = model(input_image)\n",
    "    loss = loss_object(input_label, prediction)\n",
    "\n",
    "  # Get the gradients of the loss w.r.t to the input image.\n",
    "  gradient = tape.gradient(loss, input_image)\n",
    "  # Get the sign of the gradients to create the perturbation\n",
    "  signed_grad = tf.sign(gradient)\n",
    "  return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbations = create_adversarial_pattern(model, image, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0, 0.005, 0.01, 0.1]\n",
    "\n",
    "for eps in epsilons:\n",
    "\n",
    "    del_x = perturbations.numpy() * eps\n",
    "\n",
    "    adv_image = image + del_x\n",
    "\n",
    "\n",
    "    # Predict and plot\n",
    "    adv_pred = model.predict(adv_image)\n",
    "\n",
    "    # plot points with predicted class and label\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n",
    "    ax.scatter(adv_image[0, :, 0], adv_image[0, :, 1], adv_image[0, :, 2], marker = '.')\n",
    "    ax.set_axis_off()\n",
    "    ax.view_init(5, 15)\n",
    "    plt.title(eps)\n",
    "    plt.show()\n",
    "    \n",
    "    print(np.argmax(adv_pred), np.max(adv_pred))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going with 2D Mnist dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "num_classes = 10\n",
    "input_shape = (30, 30, 1)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train_2d_sel, y_train_sel_b, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points, labels = x_test_2d_sel[-8:], y_test_sel_b[-8:]\n",
    "\n",
    "# run test data through model\n",
    "preds = model.predict(points)\n",
    "preds = tf.math.argmax(preds, -1)\n",
    "labels = np.argmax(labels, axis = 1)\n",
    "\n",
    "\n",
    "# plot points with predicted class and label\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "for i in range(8):\n",
    "\n",
    "    print(f\"pred: {preds[i].numpy()}, label: {labels[i]}\") #.format(preds[i].numpy(), labels.numpy()[i])\n",
    "\n",
    "    ax = fig.add_subplot(2, 4, i + 1)\n",
    "\n",
    "    ax.imshow(points[i, :, :, 0])\n",
    "    \n",
    "    ax.set_title(\n",
    "        \"pred: {:}, label: {:}\".format(\n",
    "            preds[i].numpy(), labels[i]\n",
    "        )\n",
    "    )\n",
    "    ax.set_axis_off()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating adversarial attacks for Mnist2d\n",
    "# \n",
    "image = x_test_2d_sel[0:1]\n",
    "label = y_test_sel_b[0:1]\n",
    "\n",
    "image = tf.convert_to_tensor(image)\n",
    "label = tf.convert_to_tensor(label)\n",
    "\n",
    "perturbations = create_adversarial_pattern(model, image, label)\n",
    "\n",
    "# epsilons = [0, 0.005, 0.01, 0.05]\n",
    "epsilons = [0, 0.005, 0.01, 0.1]\n",
    "\n",
    "\n",
    "for eps in epsilons:\n",
    "\n",
    "    del_x = perturbations.numpy() * eps\n",
    "\n",
    "    adv_image = image + del_x\n",
    "\n",
    "\n",
    "    # Predict and plot\n",
    "    adv_pred = model.predict(adv_image)\n",
    "    adv_pred_int = np.argmax(adv_pred)\n",
    "    adv_prob = int(np.max(adv_pred)*100)\n",
    "\n",
    "    # plot points with predicted class and label\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = fig.add_subplot(2, 4, i + 1)\n",
    "    ax.imshow(adv_image[0, :, :, 0])\n",
    "    ax.set_axis_off()\n",
    "    plt.title(f\"$\\epsilon$: {eps}, Pred: {adv_pred_int} with {adv_prob}%\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_3D = keras.Input(shape=(NUM_POINTS, 3))\n",
    "inputs_2D = (30, 30, 1)\n",
    "\n",
    "# Extracting features from 3D points...\n",
    "x = tnet(inputs_3D, 3)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = tnet(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 512)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 128)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "feat_3d = Model(inputs=inputs_3D, outputs=x)\n",
    "feat_3d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_3D = keras.Input(shape=(NUM_POINTS, 3))\n",
    "inputs_2D = (30, 30, 1)\n",
    "\n",
    "# Extracting features from 3D points...\n",
    "x = tnet(inputs_3D, 3)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = tnet(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 512)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 128)\n",
    "# x = layers.Dropout(0.3)(x)\n",
    "feat_3d = Model(inputs=inputs_3D, outputs=x)\n",
    "\n",
    "# Extracting features from 2D points... \n",
    "\n",
    "feat_2d = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=inputs_2D),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Feature fusion from 3D points and 2D Image...\n",
    "\n",
    "\n",
    "# combine the output of the two branches\n",
    "combined = concatenate([feat_2d.output, feat_3d.output])\n",
    "# apply a FC layer and then a regression prediction on the\n",
    "z = Dense(64, activation=\"relu\")(combined)\n",
    "z = Dense(num_classes, activation=\"softmax\")(z)\n",
    "\n",
    "\n",
    "# Finally combine two models and build a single multi modal mode...\n",
    "model_fusion = Model(inputs=[feat_2d.input, feat_3d.input], outputs=z,  name=\"mid-fusion\")\n",
    "model_fusion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling fusion model...\n",
    "# Train the model\n",
    "\n",
    "batch_size = 24\n",
    "epochs = 10\n",
    "\n",
    "model_fusion.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model_fusion.fit([x_train_2d_sel, x_train_3d_sel], y_train_sel_b, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions and images...\n",
    "\n",
    "images, points, labels = x_test_2d_sel[:4], x_test_3d_sel[:4], y_test_sel_b[:4]\n",
    "\n",
    "# run test data through model\n",
    "preds = model_fusion.predict([images, points])\n",
    "preds = tf.math.argmax(preds, -1)\n",
    "labels = np.argmax(labels, axis = 1)\n",
    "\n",
    "\n",
    "# plot points with predicted class and label\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "for i in range(4):\n",
    "\n",
    "    print(f\"pred: {preds[i].numpy()}, label: {labels[i]}\") #.format(preds[i].numpy(), labels.numpy()[i])\n",
    "\n",
    "    ax = fig.add_subplot(2, 4, 2*i + 1)\n",
    "    ax.imshow(images[i, :, :, 0])\n",
    "    ax.set_title(\n",
    "        \"pred: {:}, label: {:}\".format(\n",
    "            preds[i].numpy(), labels[i]\n",
    "        )\n",
    "    )\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    ax = fig.add_subplot(2, 4, 2*i + 2, projection=\"3d\")    \n",
    "    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2], marker='.')\n",
    "    ax.set_title(\n",
    "        \"pred: {:}, label: {:}\".format(\n",
    "            preds[i].numpy(), labels[i]\n",
    "        )\n",
    "    )\n",
    "    # ax.set_axis_off()\n",
    "    ax.view_init(0, 10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adversarial samples...\n",
    "images, points, labels = x_test_2d_sel[-1:], x_test_3d_sel[-1:], y_test_sel_b[-1:]\n",
    "input_sample = [tf.convert_to_tensor(images[0:1]), tf.convert_to_tensor(points[0:1])]\n",
    "input_label = tf.convert_to_tensor(labels[0:1])\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "\n",
    "# def create_adversarial_pattern(model, input_image, input_label):\n",
    "# return purturbatiuon\n",
    "# perturbations = create_adversarial_pattern(model, image, label)\n",
    "\n",
    "  \n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(input_sample)\n",
    "  prediction = model_fusion(input_sample)\n",
    "  loss = loss_object(input_label, prediction)\n",
    "\n",
    "  # Get the gradients of the loss w.r.t to the input image.\n",
    "  gradient = tape.gradient(loss, input_sample)\n",
    "  # Get the sign of the gradients to create the perturbation\n",
    "  perturbations_sign_2d = tf.sign(gradient[0]).numpy()\n",
    "  perturbations_sign_3d = tf.sign(gradient[1]).numpy()\n",
    "# Visualize purturbation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsilons = [0, 0.005, 0.01, 0.05]\n",
    "epsilons = [0, 0.005, 0.01, 0.05, 0.1] #, 10, 100]\n",
    "\n",
    "for eps in epsilons:\n",
    "\n",
    "    eps_2d = eps\n",
    "    eps_3d = eps\n",
    "\n",
    "    del_x_2d = perturbations_sign_2d * eps_2d\n",
    "    del_x_3d = perturbations_sign_3d * eps_3d\n",
    "\n",
    "    adv_image = images + del_x_2d\n",
    "    adv_point = points + del_x_3d\n",
    "\n",
    "    # Predict and plot\n",
    "    adv_pred = model_fusion.predict([adv_image, adv_point])\n",
    "    adv_pred_int = np.argmax(adv_pred)\n",
    "    adv_prob = int(np.max(adv_pred)*100)\n",
    "\n",
    "    # plot points with predicted class and label\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    \n",
    "    # Plotting 2D images...\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.imshow(adv_image[0, :, :, 0])\n",
    "    # ax.set_title(\"Adversarial image\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # Plotting 3D clound points...\n",
    "    ax = fig.add_subplot(1, 2, 2, projection=\"3d\")    \n",
    "    adv_point = adv_point[:, ::, :]\n",
    "    ax.scatter(adv_point[0, :, 0], adv_point[0, :, 1], adv_point[0, :, 2], marker='.')\n",
    "    # ax.set_title(\"Adversarial point clouds\")\n",
    "    # ax.set_axis_off()\n",
    "    ax.view_init(0, 5)\n",
    "\n",
    "    fig.suptitle(f\"$\\epsilon$: {eps}, Pred: {adv_pred_int} with {adv_prob}%\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    " \n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(5,5)\n",
    " \n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    # Get the point from the points list at index i\n",
    "    point = points[i]\n",
    "    # Plot that point using the x and y coordinates\n",
    "    ax.plot(point[0], point[1], color='green', \n",
    "            label='original', marker='o')\n",
    "    # Set the x and y axis to display a fixed range\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "ani = FuncAnimation(fig, animate, frames=len(points),\n",
    "                    interval=500, repeat=False)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "from matplotlib.animation import PillowWriter\n",
    "# Save the animation as an animated GIF\n",
    "ani.save(\"plots/simple_animation.gif\", dpi=300,\n",
    "         writer=PillowWriter(fps=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_point.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "pd.DataFrame(del_x_3d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging layers to consider --\n",
    "- Concatenate layer\n",
    "- Average layer\n",
    "- Maximum layer\n",
    "- Minimum layer\n",
    "- Add layer\n",
    "- Subtract layer\n",
    "- Multiply layer\n",
    "- Dot layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and plot\n",
    "adv_pred = model_fusion.predict([adv_image, adv_point])\n",
    "\n",
    "print(adv_pred)\n",
    "\n",
    "adv_pred_int = np.argmax(adv_pred)\n",
    "\n",
    "print(adv_pred_int)\n",
    "\n",
    "adv_prob = int(np.max(adv_pred)*100)\n",
    "\n",
    "print(adv_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_point.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a fusion model....\n",
    "\n",
    "# define two sets of inputs\n",
    "inputA = Input(shape=(32,))\n",
    "inputB = Input(shape=(128,))\n",
    "# the first branch operates on the first input\n",
    "x = Dense(8, activation=\"relu\")(inputA)\n",
    "x = Dense(4, activation=\"relu\")(x)\n",
    "\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "# the second branch opreates on the second input\n",
    "y = Dense(64, activation=\"relu\")(inputB)\n",
    "y = Dense(32, activation=\"relu\")(y)\n",
    "y = Dense(4, activation=\"relu\")(y)\n",
    "\n",
    "\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "\n",
    "\n",
    "# combine the output of the two branches\n",
    "combined = concatenate([x.output, y.output])\n",
    "# apply a FC layer and then a regression prediction on the\n",
    "# combined outputs\n",
    "z = Dense(2, activation=\"relu\")(combined)\n",
    "z = Dense(1, activation=\"relu\")(z)\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_A = np.random.randn(100, 32)\n",
    "x_B = np.random.randn(100, 128)\n",
    "y = np.array([0, 1]*50)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# model.fit(x_train_3d_sel, y_train_sel_b, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([x_A, x_B], y, batch_size=10, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([x_A[:10], x_B[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating adversarial attacks for Mnist2d\n",
    "# \n",
    "import tensorflow as tf\n",
    "# image = [x_A[0:1], x_B[0:1]]\n",
    "label = y[:1]\n",
    "\n",
    "# image = tf.convert_to_tensor(image)\n",
    "# label = tf.convert_to_tensor(label)\n",
    "\n",
    "image = [tf.convert_to_tensor(x_A[0:1]), tf.convert_to_tensor(x_B[0:1])]\n",
    "label = tf.convert_to_tensor(label)\n",
    "\n",
    "\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "input_image = image\n",
    "input_label = label\n",
    "\n",
    "# def create_adversarial_pattern(model, input_image, input_label):\n",
    "  \n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(input_image)\n",
    "  prediction = model(input_image)\n",
    "  loss = loss_object(input_label, prediction)\n",
    "\n",
    "  # Get the gradients of the loss w.r.t to the input image.\n",
    "  gradient = tape.gradient(loss, input_image)\n",
    "  # Get the sign of the gradients to create the perturbation\n",
    "  # signed_grad = tf.sign(gradient)\n",
    "\n",
    "\n",
    "# perturbations = create_adversarial_pattern(model, image, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sign(gradient[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sign(gradient[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='plots/fusion_AB.jpg', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.heatmap(pd.DataFrame(x_train_2d[0,:, :, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "# model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "\n",
    "# model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "model.fit(train_dataset_2d, epochs = 5, validation_data=test_dataset_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "# # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train_sel, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test_sel, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(pd.DataFrame(x_train[0,:, :, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2d = x_train_2d.reshape(-1, 30, 30, 1)\n",
    "x_test_2d = x_test_2d.reshape(-1, 30, 30, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "\n",
    "num_classes = 10\n",
    "input_shape = (30, 30, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "# model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "\n",
    "# model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "model.fit(train_dataset_2d, epochs = 5, validation_data=test_dataset_2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model...\n",
    "model.save('models/mnist2d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model\n",
    "model = keras.models.load_model('models/mnist2d')\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('venv-mms': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d675873c32fed3b44a830c158dd9a059bc5f8e92f71d85b643472577f19e7603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
