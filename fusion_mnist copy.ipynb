{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This repo contains the following:\n",
    "- Code for CNN-based classification for MNIST Dataset\n",
    "- Code for Pointnet classification for MNIST3d Dataset\n",
    "- Code for Fusion-based classification for MNIST and MNIST3D Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "tf.random.set_seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for device in gpu_devices:\n",
    "#     tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '../data/multimodal/mnist3d/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File(DATADIR + 'full_dataset_vectors.h5', 'r') as dataset:\n",
    "#     X_train = dataset['X_train'][:]\n",
    "#     X_test = dataset['X_test'][:]\n",
    "#     y_train = dataset['y_train'][:]\n",
    "#     y_test = dataset['y_test'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noOfpoints = 1024\n",
    "BATCH_SIZE = 32\n",
    "run_type = 'demo'\n",
    "run_type = 'full'\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "NUM_POINTS = noOfpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(DATADIR + 'train_point_clouds.h5', 'r') as points_dataset:\n",
    "\n",
    "    # Array to store data...\n",
    "    x_train_2d = []\n",
    "    x_train_3d = []\n",
    "    y_train = [] \n",
    "\n",
    "    # Looping over the whole dataset..\n",
    "    for i, (key, sample) in enumerate(points_dataset.items()):\n",
    "        \n",
    "        # Saving images...\n",
    "        x_train_2d.append(sample['img'][:])\n",
    "\n",
    "        # Sampling point cloud and saving...\n",
    "        pointCloud = sample['points'][:]\n",
    "        num_of_rows = pointCloud.shape[0]\n",
    "        random_ind = np.random.choice(num_of_rows, size=noOfpoints, replace=False)\n",
    "        pointCloud = pointCloud[random_ind, :]\n",
    "        x_train_3d.append(pointCloud)\n",
    "\n",
    "        # Ssaving labels...\n",
    "        y_train.append(sample.attrs['label'])\n",
    "\n",
    "# converting to np array...\n",
    "x_train_2d = np.stack(x_train_2d)\n",
    "x_train_3d = np.stack(x_train_3d)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(DATADIR + 'test_point_clouds.h5', 'r') as points_dataset:\n",
    "\n",
    "    # Array to store data...\n",
    "    x_test_2d = []\n",
    "    x_test_3d = []\n",
    "    y_test = [] \n",
    "\n",
    "    # Looping over the whole dataset..\n",
    "    for i, (key, sample) in enumerate(points_dataset.items()):\n",
    "        \n",
    "        # Saving images...\n",
    "        x_test_2d.append(sample['img'][:])\n",
    "\n",
    "        # Sampling point cloud and saving...\n",
    "        pointCloud = sample['points'][:]\n",
    "        num_of_rows = pointCloud.shape[0]\n",
    "        random_ind = np.random.choice(num_of_rows, size=noOfpoints, replace=False)\n",
    "        pointCloud = pointCloud[random_ind, :]\n",
    "        x_test_3d.append(pointCloud)\n",
    "\n",
    "        # Ssaving labels...\n",
    "        y_test.append(sample.attrs['label'])\n",
    "\n",
    "# converting to np array...\n",
    "x_test_2d = np.stack(x_test_2d)\n",
    "x_test_3d = np.stack(x_test_3d)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset for mnist 3D data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding extra...\n",
    "\n",
    "total_training_samples = x_train_3d.shape[0]\n",
    "total_testing_samples = x_test_3d.shape[0]\n",
    "\n",
    "random_trainig_indices = np.arange(total_training_samples)\n",
    "np.random.shuffle(random_trainig_indices)\n",
    "\n",
    "random_testing_indices = np.arange(total_testing_samples)\n",
    "np.random.shuffle(random_testing_indices)\n",
    "\n",
    "\n",
    "print(f\"No of training samples: {x_train_3d.shape[0]}\")\n",
    "print(f\"No of testing samples: {x_test_3d.shape[0]}\")\n",
    "\n",
    "\n",
    "if run_type == 'demo':\n",
    "    demo_training_samples = 100\n",
    "    demo_testing_samples = 100\n",
    "\n",
    "    random_trainig_indices = random_trainig_indices[0:demo_training_samples]\n",
    "    random_testing_indices = random_testing_indices[0:demo_testing_samples]\n",
    "\n",
    "x_train_3d_sel = x_train_3d[random_trainig_indices]\n",
    "y_train_selected = y_train[random_trainig_indices]\n",
    "\n",
    "test_points_selected = x_test_3d[random_testing_indices]\n",
    "test_labels_selected = y_test[random_testing_indices]\n",
    "\n",
    "print(\"After updating...\")\n",
    "print(f\"No of training samples: {x_train_3d_sel.shape[0]}\")\n",
    "print(f\"No of testing samples: {test_points_selected.shape[0]}\")\n",
    "print(\"Done...!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(points, label):\n",
    "    # jitter points\n",
    "    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n",
    "    # shuffle points\n",
    "    points = tf.random.shuffle(points)\n",
    "    return points, label\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_3d, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_3d, y_test))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(len(x_train_3d)).map(augment).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.shuffle(len(x_test_3d)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model\n",
    "\n",
    "Each convolution and fully-connected layer (with exception for end layers) consits of\n",
    "Convolution / Dense -> Batch Normalization -> ReLU Activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PointNet consists of two core components. The primary MLP network, and the transformer\n",
    "net (T-net). The T-net aims to learn an affine transformation matrix by its own mini\n",
    "network. The T-net is used twice. The first time to transform the input features (n, 3)\n",
    "into a canonical representation. The second is an affine transformation for alignment in\n",
    "feature space (n, 3). As per the original paper we constrain the transformation to be\n",
    "close to an orthogonal matrix (i.e. ||X*X^T - I|| = 0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can then define a general function to build T-net layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tnet(inputs, num_features):\n",
    "\n",
    "    # Initalise bias as the indentity matrix\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "\n",
    "    x = conv_bn(inputs, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    # Apply affine transformation to input features\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main network can be then implemented in the same manner where the t-net mini models\n",
    "can be dropped in a layers in the graph. Here we replicate the network architecture\n",
    "published in the original paper but with half the number of weights at each layer as we\n",
    "are using the smaller 10 class ModelNet dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
    "\n",
    "x = tnet(inputs, 3)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = tnet(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 512)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 128)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "Once the model is defined it can be trained like any other standard classification model\n",
    "using `.compile()` and `.fit()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(train_dataset, epochs = 50, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions\n",
    "\n",
    "We can use matplotlib to visualize our trained model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_dataset.take(1)\n",
    "\n",
    "points, labels = list(data)[0]\n",
    "points = points[:8, ...]\n",
    "labels = labels[:8, ...]\n",
    "\n",
    "# run test data through model\n",
    "preds = model.predict(points)\n",
    "preds = tf.math.argmax(preds, -1)\n",
    "\n",
    "points = points.numpy()\n",
    "\n",
    "# plot points with predicted class and label\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(2, 4, i + 1, projection=\"3d\")\n",
    "    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2])\n",
    "    ax.set_title(\n",
    "        \"pred: {:}, label: {:}\".format(\n",
    "            preds[i].numpy(), labels.numpy()[i]\n",
    "        )\n",
    "    )\n",
    "    ax.set_axis_off()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('models/my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = ...  # Get model (Sequential, Functional Model, or Model subclass)\n",
    "# model.save('models/mnist3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def augment(points, label):\n",
    "#     # jitter points\n",
    "#     points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n",
    "#     # shuffle points\n",
    "#     points = tf.random.shuffle(points)\n",
    "#     return points, label\n",
    "\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_points_selected, train_labels_selected))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((test_points_selected, test_labels_selected))\n",
    "\n",
    "# train_dataset = train_dataset.shuffle(len(train_points)).map(augment).batch(BATCH_SIZE)\n",
    "# test_dataset = test_dataset.shuffle(len(test_points)).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(x_train_2d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(x_train_3d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2d.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(X_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([x_train_3d[0][:], x_train_3d[1][:], x_train_3d[2][:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([x_train_3d[0], x_train_3d[1], x_train_3d[2]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_3d_cut = x_train_3d[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_3d_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([x_train_3d_each, x_train_3d_each, x_train_3d_each]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x_train_3d_s = []\n",
    "\n",
    "for x_train_3d_each in x_train_3d_cut:\n",
    "\n",
    "    x_train_3d_s.append(pd.DataFrame(x_train_3d_each).values)\n",
    "\n",
    "    # points_s = []\n",
    "    \n",
    "    # for points in x_train_3d_each:\n",
    "    #     xs = []\n",
    "    #     for x in points:\n",
    "    #         xs.append(x)\n",
    "\n",
    "    #     points_s.append(xs)\n",
    "    \n",
    "    # x_train_3d_s.append(points_s)\n",
    "\n",
    "# x_train_3d_s = np.array(x_train_3d_s)\n",
    "# x_train_3d_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(x_train_3d_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(x_train_3d_s).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_3d_s = []\n",
    "x_train_3d_s.append(points_s)\n",
    "x_train_3d_s.append(points_s)\n",
    "x_train_3d_s.append(points_s)\n",
    "np.array(x_train_3d_s).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([points_s, points_s, points_s]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_3d_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(x_train_3d_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([(x.tolist()) for x in x_train_3d[0:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(pd.DataFrame(x_train_3d).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_3d.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_train_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newarray = np.dstack(x_train_3d)\n",
    "newarray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2d = np.array([])\n",
    "x_train_2d = np.vstack(x_train_2d, np.random.randn(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(x_train_3d[0:10]) #, dtype= float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(DATADIR + 'test_point_clouds.h5', 'r') as points_dataset:\n",
    "\n",
    "    # List...\n",
    "    x_test_2d = []\n",
    "    x_test_3d = []\n",
    "    y_test = [] \n",
    "\n",
    "    # Iterate over the 2D and 3D points...\n",
    "    for key, sample in points_dataset.items():\n",
    "        x_test_2d.append(sample['img'][:])\n",
    "        x_test_3d.append(sample['points'][:])\n",
    "        y_test.append(sample.attrs['label'])\n",
    "\n",
    "\n",
    "print(len(x_test_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize a pair of data points - Image and 3D points\n",
    "\n",
    "image = x_train_2d[0]\n",
    "points = x_train_3d[0][0::100]\n",
    "label = y_train[0]\n",
    "\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "# Image plot\n",
    "ax = fig.add_subplot(211)\n",
    "ax.imshow(image)\n",
    "\n",
    "# Points plot\n",
    "ax = fig.add_subplot(222, projection=\"3d\")\n",
    "ax.scatter(points[:, 0], points[:, 1], points[:, 2])\n",
    "ax.set_axis_off()\n",
    "ax.view_init(0,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for CNN-based classification for MNIST Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76b18d0804b1d18cc4a8723b732596a057f641d6427a46ef33e32599b5d9a6a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
